# Jira Worklog Aggregation in Databricks ğŸ“Š
---
ğŸ“„ ENG: Overview
---
This repository contains SQL scripts for aggregating Jira worklog data in **Databricks**. The scripts process worklogs, tasks, epics, and sub-tasks to generate a consolidated view of hours spent by users across different Jira issues. â±ï¸

## Overview ğŸŒŸ
The main goal of this project is to create a **gold-level table** in Databricks that consolidates worklog data from Jira. It handles multiple levels of Jira hierarchy:
- **Epic** ğŸ¢
- **Task / Story** ğŸ“Œ
- **Sub-task** ğŸ“

Additionally, it aggregates time spent by each author and handles multiple expense types in the data ğŸ’°.

## Data Sources ğŸ—‚ï¸
The scripts use the following source tables in the `main.data.jira.silver.data` schema:
- `tempo_worklogs` â€“ raw worklogs from Jira Tempo â±ï¸
- `users` â€“ Jira user information ğŸ‘¤
- `change_logs` â€“ Jira issue change logs ğŸ”„
- `jira_issues` â€“ Jira issues, epics, and sub-tasks ğŸ—‚ï¸
- `projects` â€“ Jira project metadata ğŸ—ï¸
- `types_for_reporting` â€“ mapping of Jira issue types to report categories ğŸ“Š

## SQL Tables ğŸ“
The main output table is:

**`main.data.jira.gold.taskdata`** â€“ contains aggregated worklog data per user, per Jira issue, with the following key columns:
- `Year`, `Month`, `START_DATE` ğŸ“…
- `TEMPO_Author_ID`, `ASSIGNEE` ğŸ‘¤
- `Epic_ID`, `Epic_SUMMARY` ğŸ¢
- `Task_ID`, `Task_SUMMARY` ğŸ“Œ
- `Sub_task_ID`, `Sub_task_SUMMARY` ğŸ“
- `Hours_spent`, `Seconds_spent` â±ï¸
- `Expense_Type` ğŸ’°

## Notes âš ï¸

The SQL script includes UNION ALL of multiple levels of Jira issues to ensure proper aggregation.

Null values for assignees or authors are replaced with 'Unassigned' ğŸ‘¤

Expense types are resolved hierarchically from three possible columns (Expense_Type_1, Expense_Type_2, Expense_Type_3) ğŸ’°

Output is ordered by Year, Month, and user/issue hierarchy ğŸ“…
---
ğŸ“„ DE: Ãœbersicht
---
Dieses Repository enthÃ¤lt SQL-Skripte zum Aggregieren von Jira-Arbeitsprotokoll-Daten in **Databricks**. Die Skripte verarbeiten Arbeitsprotokolle, Aufgaben, Epics und Unteraufgaben, um eine konsolidierte Ansicht der von Benutzern fÃ¼r verschiedene Jira-Issues aufgewendeten Stunden zu erstellen. â±ï¸

## Ãœbersicht ğŸŒŸ
Das Hauptziel dieses Projekts ist die Erstellung einer **Gold-Level-Tabelle** in Databricks, die Arbeitsprotokoll-Daten aus Jira konsolidiert. Es verarbeitet mehrere Ebenen der Jira-Hierarchie:
- **Epic** ğŸ¢
- **Aufgabe / Story** ğŸ“Œ
- **Unteraufgabe** ğŸ“

DarÃ¼ber hinaus aggregiert es die von jedem Autor aufgewendete Zeit und verarbeitet mehrere Ausgabentypen in den Daten ğŸ’°.

## Datenquellen ğŸ—‚ï¸
Die Skripte verwenden die folgenden Quelltabellen im Schema `main.data.jira.silver.data`:
- `tempo_worklogs` â€“ Rohdaten aus Jira Tempo â±ï¸
- `users` â€“ Jira-Benutzerinformationen ğŸ‘¤
- `change_logs` â€“ Jira-Ã„nderungsprotokolle ğŸ”„
- `jira_issues` â€“ Jira-VorgÃ¤nge, Epics und Unteraufgaben ğŸ—‚ï¸
- `projects` â€“ Jira-Projektmetadaten ğŸ—ï¸
- `types_for_reporting` â€“ Zuordnung von Jira-Issue-Typen zu Berichtskategorien ğŸ“Š

## SQL-Tabellen ğŸ“
Die Hauptausgabetabelle lautet:

**`main.data.jira.gold.taskdata`** â€“ enthÃ¤lt aggregierte Arbeitsprotokoll-Daten pro Benutzer und pro Jira-Issue mit den folgenden SchlÃ¼sselspalten:
- `Jahr`, `Monat`, `START_DATE` ğŸ“…
- `TEMPO_Author_ID`, `ASSIGNEE` ğŸ‘¤
- `Epic_ID`, `Epic_SUMMARY` ğŸ¢
- `Task_ID`, `Task_SUMMARY` ğŸ“Œ
- `Sub_task_ID`, `Sub_task_SUMMARY` ğŸ“
- `Hours_spent`, `Seconds_spent` â±ï¸
- `Expense_Type` ğŸ’°

## Hinweise âš ï¸
Das SQL-Skript enthÃ¤lt UNION ALL fÃ¼r mehrere Ebenen von Jira-VorgÃ¤ngen, um eine korrekte Aggregation sicherzustellen.

Nullwerte fÃ¼r Bearbeiter oder Autoren werden durch â€Nicht zugewiesenâ€œ ersetzt ğŸ‘¤.

Ausgabentypen werden hierarchisch aus drei mÃ¶glichen Spalten (Expense_Type_1, Expense_Type_2, Expense_Type_3) aufgelÃ¶st ğŸ’°.

Die Ausgabe ist nach Jahr, Monat und Benutzer-/Issue-Hierarchie sortiert ğŸ“….
